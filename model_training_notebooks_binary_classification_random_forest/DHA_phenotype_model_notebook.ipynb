{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence8.fa\n",
      "ERR029411_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence24.fa\n",
      "ERR012425_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence10.fa\n",
      "ERR012227_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence14.fa\n",
      "ERR012269_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence20.fa\n",
      "ERR012330_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence30.fa\n",
      "ERR012494_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence15.fa\n",
      "ERR012274_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence21.fa\n",
      "ERR012353_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence31.fa\n",
      "ERR012509_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence9.fa\n",
      "ERR205935_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence11.fa\n",
      "ERR012228_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence2.fa\n",
      "ERR012328_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence6.fa\n",
      "ERR029095.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence7.fa\n",
      "ERR029096_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence3.fa\n",
      "ERR012493_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence28.fa\n",
      "ERR012469_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence4.fa\n",
      "ERR012762_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence18.fa\n",
      "ERR012311_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence19.fa\n",
      "ERR012317_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence1.fa\n",
      "ERR012226_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence29.fa\n",
      "ERR012481_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence5.fa\n",
      "ERR029083_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence16.fa\n",
      "ERR012277_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence22.fa\n",
      "ERR012409_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence32.fa\n",
      "ERR012518_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence26.fa\n",
      "ERR012446_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence12.fa\n",
      "ERR012232_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence27.fa\n",
      "ERR012462_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence13.fa\n",
      "ERR012260_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence17.fa\n",
      "ERR012287_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence23.fa\n",
      "ERR012424_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence33.fa\n",
      "ERR012519_1.fastq\n",
      "First few rows of the DataFrame:\n",
      "         sequence_id                                           sequence\n",
      "0  ERR029411_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "1  ERR012425_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "2  ERR012227_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "3  ERR012269_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "4  ERR012330_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "\n",
      "DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   sequence_id  32 non-null     object\n",
      " 1   sequence     32 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 640.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Correct path to your directory containing FASTA files\n",
    "# fasta_dir = r\"C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\"\n",
    "fasta_dir = r\"/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences\"\n",
    "# List to store sequence data\n",
    "sequences_data = []\n",
    "\n",
    "# Loop through each FASTA file in the directory\n",
    "for fasta_file in os.listdir(fasta_dir):\n",
    "    if fasta_file.endswith(\".fa\") or fasta_file.endswith(\".fasta\"):\n",
    "        file_path = os.path.join(fasta_dir, fasta_file)\n",
    "        print(file_path)\n",
    "        record_seq=\"\"\n",
    "        record_id=\"\"\n",
    "        for n,record in enumerate(SeqIO.parse(file_path, \"fasta\")):\n",
    "            if (n==0):\n",
    "                record_id=record.id\n",
    "            record_seq=record_seq+str(record.seq)\n",
    "        print(record_id)\n",
    "        sequences_data.append({\n",
    "            \"sequence_id\": record_id,\n",
    "            \"sequence\": str(record_seq)\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the sequence data\n",
    "df = pd.DataFrame(sequences_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# inspect the DataFrame's structure\n",
    "print(\"\\nDataFrame Information:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to my data\n",
    "labels_file_path = r'/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/csv_dataset_files/DHA_phenotype_dataset.csv'\n",
    "\n",
    "# Function to read FASTA files from a directory and extract sequences\n",
    "def read_fasta_from_dir(dir_path):\n",
    "    sequences = {}\n",
    "    for fasta_file in os.listdir(dir_path):\n",
    "        if fasta_file.endswith(\".fa\") or fasta_file.endswith(\".fasta\"):\n",
    "            file_path = os.path.join(dir_path, fasta_file)\n",
    "            for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "                sequences[record.id] = str(record.seq)\n",
    "    return sequences\n",
    "\n",
    "# Function to one-hot encode the sequence\n",
    "def one_hot_encode(seq):\n",
    "    print(\"---------------\"+str(len(seq)))\n",
    "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
    "    # return np.array([mapping[nuc] for nuc in seq.upper() if nuc in mapping])\n",
    "    return np.array([mapping[nuc] for n,nuc in enumerate(seq.upper()) if ((n<1000000))])\n",
    "\n",
    "# Read sequences from the FASTA directory\n",
    "sequences = read_fasta_from_dir(fasta_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/csv_dataset_files/DHA_phenotype_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Debug: Check if the file exists\n",
    "if os.path.exists(labels_file_path):\n",
    "    print(f\"File exists: {labels_file_path}\")\n",
    "else:\n",
    "    print(f\"File not found: {labels_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read with encoding: utf-8\n"
     ]
    }
   ],
   "source": [
    "# Try reading with different encodings\n",
    "for encoding in ['utf-8', 'ISO-8859-1', 'latin1', 'cp1252']:\n",
    "    try:\n",
    "        labels_df = pd.read_csv(labels_file_path, encoding=encoding)\n",
    "        print(f\"Successfully read with encoding: {encoding}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Failed with encoding {encoding}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences read: 45\n",
      "ID: ERR029411_1.fastq, Sequence: TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaaccct...\n",
      "ID: NC_037280.1, Sequence: aaccctaaaccctaaaccctaaaccctaaaccctaaaccctaaacctaaa...\n",
      "ID: NC_000521.4, Sequence: TAAACCCTAAATCTCTAAACCCTAAAGCTATACCTAAACCCTGAAGGTTA...\n",
      "ID: NC_004318.2, Sequence: aaccctaaaccctgaaccctaaaccctaaaccctgaaccctgaaccctaa...\n",
      "ID: NC_004326.2, Sequence: ctaaaccctgaaccctaaaccctgaaccctaaaccctaaaccctgaaccc...\n",
      "Total labels read: 33\n",
      "ID: ERR012494_1.fastq, Label: Resistant\n",
      "ID: ERR012519_1.fastq, Label: Resistant\n",
      "ID: ERR012425_1.fastq, Label: Resistant\n",
      "ID: ERR012424_1.fastq, Label: Sensitive\n",
      "ID: ERR029095_1.fastq, Label: Resistant\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the sequences read\n",
    "print(f\"Total sequences read: {len(sequences)}\")\n",
    "for seq_id, seq in list(sequences.items())[:5]:  # Print first 5 sequences\n",
    "    print(f\"ID: {seq_id}, Sequence: {seq[:50]}...\")\n",
    "\n",
    "# Read labels from CSV file\n",
    "labels_df = pd.read_csv(labels_file_path)\n",
    "labels_dict = labels_df.set_index('sequence_id').to_dict()['label']  # Assuming 'label' column for binary classification\n",
    "\n",
    "# Debug: Check the labels read\n",
    "print(f\"Total labels read: {len(labels_dict)}\")\n",
    "for seq_id, label in list(labels_dict.items())[:5]:  # Print first 5 labels\n",
    "    print(f\"ID: {seq_id}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------23292141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------23287178\n",
      "---------------23292541\n",
      "---------------23292457\n",
      "---------------23289447\n",
      "---------------23270800\n",
      "---------------23287492\n",
      "---------------23286572\n",
      "---------------23274363\n",
      "---------------23292461\n",
      "---------------23285585\n",
      "---------------23285407\n",
      "---------------23292472\n",
      "---------------23292287\n",
      "---------------23286900\n",
      "---------------23251041\n",
      "---------------23255091\n",
      "---------------23292399\n",
      "---------------23292372\n",
      "---------------23265735\n",
      "---------------23292244\n",
      "---------------23289777\n",
      "---------------23252337\n",
      "---------------23267664\n",
      "---------------23258039\n",
      "---------------23292468\n",
      "---------------23289229\n",
      "---------------23292393\n",
      "---------------23286531\n",
      "---------------23292541\n",
      "---------------23255999\n",
      "[(4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,)]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the sequences and labels for model training\n",
    "encoded_sequences = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "df_dict = df.to_dict(\"records\")\n",
    "\n",
    "for seq_dict in df_dict:\n",
    "    if seq_dict['sequence_id'] in labels_dict:\n",
    "        # Encode the sequence and flatten it\n",
    "        encoded_sequences.append(one_hot_encode(seq_dict['sequence'].upper()).flatten())\n",
    "        # Append the corresponding label(s) from the dictionary\n",
    "        labels.append(labels_dict[seq_dict['sequence_id']].split(','))\n",
    "\n",
    "# Convert labels to a suitable format for training/prediction\n",
    "# Assuming binary classification with a single label per sample:\n",
    "labels = [label[0] if isinstance(label, list) else label for label in labels]\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert encoded sequences to a numpy array\n",
    "print([f.shape for f in encoded_sequences])\n",
    "encoded_sequences = np.array(encoded_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print (encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Resistant' 'Resistant' 'Resistant' 'Sensitive' 'Sensitive' 'Resistant'\n",
      " 'Resistant' 'Sensitive' 'Sensitive' 'Resistant' 'Resistant' 'Sensitive'\n",
      " 'Resistant' 'Resistant' 'Resistant' 'Resistant' 'Sensitive' 'Resistant'\n",
      " 'Sensitive' 'Resistant' 'Resistant' 'Resistant' 'Resistant' 'Sensitive'\n",
      " 'Sensitive' 'Sensitive' 'Resistant' 'Sensitive' 'Sensitive' 'Sensitive'\n",
      " 'Resistant']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded sequences shape: (31, 4000000)\n",
      "First encoded sequence: [0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the encoded sequences\n",
    "print(f\"Encoded sequences shape: {encoded_sequences.shape}\")\n",
    "if encoded_sequences.size > 0:\n",
    "    print(f\"First encoded sequence: {encoded_sequences[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 4000000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Resistant', 'Resistant', 'Resistant', 'Sensitive', 'Sensitive',\n",
       "       'Resistant', 'Resistant', 'Sensitive', 'Sensitive', 'Resistant',\n",
       "       'Resistant', 'Sensitive', 'Resistant', 'Resistant', 'Resistant',\n",
       "       'Resistant', 'Sensitive', 'Resistant', 'Sensitive', 'Resistant',\n",
       "       'Resistant', 'Resistant', 'Resistant', 'Sensitive', 'Sensitive',\n",
       "       'Sensitive', 'Resistant', 'Sensitive', 'Sensitive', 'Sensitive',\n",
       "       'Resistant'], dtype='<U9')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (24, 4000000)\n",
      "y_train shape: (24,)\n",
      "Unique labels in y_train: ['Resistant' 'Sensitive']\n",
      "#####################################################\n",
      "----- CV ---  1\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(52386) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52387) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52388) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52389) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52390) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52391) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52392) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52396) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 2}\n",
      "Best cross-validation score: 0.68\n",
      "Model is fitted. Proceeding with predictions.\n",
      "Accuracy : 0.6\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  2\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 2}\n",
      "Best cross-validation score: 0.48\n",
      "Model is fitted. Proceeding with predictions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  3\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 4}\n",
      "Best cross-validation score: 0.58\n",
      "Model is fitted. Proceeding with predictions.\n",
      "Accuracy : 0.6\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  4\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 4}\n",
      "Best cross-validation score: 0.63\n",
      "Model is fitted. Proceeding with predictions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 2}\n",
      "Best cross-validation score: 0.60\n",
      "Model is fitted. Proceeding with predictions.\n",
      "Accuracy : 0.75\n",
      "***************************\n",
      "--------------------------------------------------\n",
      "Mean accuracy:  0.67\n",
      "Stdev accuracy:  0.09746794344808966\n",
      "--------------------------------------------------\n",
      "Mean precision:  0.3\n",
      "Stdev precision:  0.4472135954999579\n",
      "--------------------------------------------------\n",
      "Mean recall:  0.16666666666666666\n",
      "Stdev recall:  0.23570226039551584\n",
      "--------------------------------------------------\n",
      "Mean f1:  0.2\n",
      "Stdev f1:  0.27386127875258304\n",
      "--------------------------------------------------\n",
      "Mean roc_auc:  0.3916666666666667\n",
      "Stdev roc_auc:  0.19454362549881252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import statistics\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "# Assuming encoded_sequences and labels have been correctly prepared\n",
    "if len(encoded_sequences) > 0 and len(labels) > 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        encoded_sequences, \n",
    "        labels, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Ensure y_train and y_test are 1D arrays\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "\n",
    "    # Print to debug shape and unique labels\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"Unique labels in y_train:\", np.unique(y_train))\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [2, 4, 8],\n",
    "        'max_depth': [1, 5, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    ls_accuracy = []\n",
    "    ls_precision = []\n",
    "    ls_recall = []\n",
    "    ls_f1 = []\n",
    "    ls_roc_auc = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        print(\"#####################################################\")\n",
    "        print(\"----- CV --- \", (i + 1))\n",
    "\n",
    "        # Create a new RandomForestClassifier instance for each fold\n",
    "        clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        X_train_cv = X_train[train_index]\n",
    "        X_test_cv = X_train[test_index]\n",
    "\n",
    "        y_train_cv = y_train[train_index]\n",
    "        y_test_cv = y_train[test_index]\n",
    "\n",
    "        # Perform grid search, which fits the model\n",
    "        grid_search = GridSearchCV(clf, param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "        grid_search.fit(X_train_cv, y_train_cv)  # Model is fitted during this process\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print(\"Best parameters found: \", grid_search.best_params_)\n",
    "        print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "        # Use the best estimator from grid search (this is the fitted model)\n",
    "        best_clf = grid_search.best_estimator_\n",
    "\n",
    "        # *** Added Debugging ***\n",
    "        # Checking if the model is actually fitted before predictions\n",
    "        try:\n",
    "            if not hasattr(best_clf, \"n_estimators\"):\n",
    "                raise NotFittedError(\"Model is not properly fitted. Ensure fit() has been called.\")\n",
    "            print(\"Model is fitted. Proceeding with predictions.\")\n",
    "\n",
    "            # Predict using the fitted model\n",
    "            y_pred = best_clf.predict(X_test_cv)\n",
    "            y_proba = best_clf.predict_proba(X_test_cv)[:, 1]\n",
    "\n",
    "            # Calculate and print performance metrics\n",
    "            accuracy = accuracy_score(y_test_cv, y_pred)\n",
    "            precision = precision_score(y_test_cv, y_pred, pos_label='Sensitive')\n",
    "            recall = recall_score(y_test_cv, y_pred, pos_label='Sensitive')\n",
    "            f1 = f1_score(y_test_cv, y_pred, pos_label='Sensitive')\n",
    "\n",
    "            # Check for the ROC AUC score (only if y_test_cv has more than one class)\n",
    "            roc_auc = 0\n",
    "            if (np.unique(y_test_cv).shape[0] > 1) and (np.unique(y_proba).shape[0] > 1):\n",
    "                roc_auc = roc_auc_score(y_test_cv, y_proba)\n",
    "\n",
    "            print(\"Accuracy :\", accuracy)\n",
    "            print(\"***************************\")\n",
    "\n",
    "            # Append results to lists for later aggregation\n",
    "            ls_accuracy.append(accuracy)\n",
    "            ls_precision.append(precision)\n",
    "            ls_recall.append(recall)\n",
    "            ls_f1.append(f1)\n",
    "            ls_roc_auc.append(roc_auc)\n",
    "\n",
    "        except NotFittedError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue  # Skip the current fold if model is not fitted\n",
    "\n",
    "    # Print aggregated results\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean accuracy: \", np.mean(np.array(ls_accuracy)))\n",
    "    print(\"Stdev accuracy: \", statistics.stdev(ls_accuracy))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean precision: \", np.mean(np.array(ls_precision)))\n",
    "    print(\"Stdev precision: \", statistics.stdev(ls_precision))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean recall: \", np.mean(np.array(ls_recall)))\n",
    "    print(\"Stdev recall: \", statistics.stdev(ls_recall))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean f1: \", np.mean(np.array(ls_f1)))\n",
    "    print(\"Stdev f1: \", statistics.stdev(ls_f1))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean roc_auc: \", np.mean(np.array(ls_roc_auc)))\n",
    "    print(\"Stdev roc_auc: \", statistics.stdev(ls_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_imp=best_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000000,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_imp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.5]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in fts_imp if _>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_index=np.where(fts_imp>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2517131, 3827706]),)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sequences.shape[1]/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "i=0\n",
    "\n",
    "ls_i=[]\n",
    "\n",
    "while(counter<encoded_sequences.shape[1]):\n",
    "    \n",
    "    counter_old=counter\n",
    "    counter=counter+4\n",
    "    \n",
    "    for g in range(4):\n",
    "        # print(\"n\")\n",
    "        _\n",
    "    \n",
    "    for k in imp_index[0]:\n",
    "\n",
    "        if (k>=counter_old and k<=counter):\n",
    "            ls_i.append(i)\n",
    "            \n",
    "    i=i+1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[629282, 956926]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_f={}\n",
    "for f in ls_i:\n",
    "    dict_f[f]=[]\n",
    "    \n",
    "for seq_dict in df_dict:\n",
    "    if seq_dict['sequence_id'] in labels_dict:\n",
    "        for f in ls_i:\n",
    "            dict_f[f].append(seq_dict['sequence'].upper()[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{629282: ['T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'G'],\n",
       " 956926: ['C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dict_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with pickle.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# # # Assume X_train and y_train are already defined\n",
    "# # # X_train: Features for training\n",
    "# # # y_train: Labels for training\n",
    "\n",
    "# # # Step 1: Create and fit the RandomForest model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# # # Step 2: Fit the model with training data\n",
    "state_changed = model.fit(X_train, y_train)\n",
    "\n",
    "# # # Step 3: Save the fitted model\n",
    "try:\n",
    "    with open('/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/pickle_files/DHA_phenotype.pkl', 'wb') as f:\n",
    "        pickle.dump(state_changed, f)\n",
    "    print(\"Model saved with pickle.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model with pickle: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved as 'DHA_phenotype_datadict.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame.from_dict(dict_f)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "# df.to_csv('datadict.csv', index=False)\n",
    "df.to_csv('/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/datadict_files/DHA_phenotype_datadict.csv', index=False)\n",
    "\n",
    "print(\"Dictionary saved as 'DHA_phenotype_datadict.csv'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
