{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence8.fa\n",
      "ERR029411_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence24.fa\n",
      "ERR012425_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence10.fa\n",
      "ERR012227_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence14.fa\n",
      "ERR012269_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence20.fa\n",
      "ERR012330_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence30.fa\n",
      "ERR012494_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence15.fa\n",
      "ERR012274_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence21.fa\n",
      "ERR012353_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence31.fa\n",
      "ERR012509_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence9.fa\n",
      "ERR205935_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence11.fa\n",
      "ERR012228_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence2.fa\n",
      "ERR012328_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence6.fa\n",
      "ERR029095.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence7.fa\n",
      "ERR029096_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence3.fa\n",
      "ERR012493_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence28.fa\n",
      "ERR012469_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence4.fa\n",
      "ERR012762_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence18.fa\n",
      "ERR012311_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence19.fa\n",
      "ERR012317_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence1.fa\n",
      "ERR012226_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence29.fa\n",
      "ERR012481_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence5.fa\n",
      "ERR029083_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence16.fa\n",
      "ERR012277_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence22.fa\n",
      "ERR012409_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence32.fa\n",
      "ERR012518_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence26.fa\n",
      "ERR012446_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence12.fa\n",
      "ERR012232_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence27.fa\n",
      "ERR012462_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence13.fa\n",
      "ERR012260_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence17.fa\n",
      "ERR012287_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence23.fa\n",
      "ERR012424_1.fastq\n",
      "/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences/consensus_sequence33.fa\n",
      "ERR012519_1.fastq\n",
      "First few rows of the DataFrame:\n",
      "         sequence_id                                           sequence\n",
      "0  ERR029411_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "1  ERR012425_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "2  ERR012227_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "3  ERR012269_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "4  ERR012330_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "\n",
      "DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   sequence_id  32 non-null     object\n",
      " 1   sequence     32 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 640.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Correct path to your directory containing FASTA files\n",
    "# fasta_dir = r\"C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\"\n",
    "fasta_dir = r\"/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/consensus_sequences\"\n",
    "# List to store sequence data\n",
    "sequences_data = []\n",
    "\n",
    "# Loop through each FASTA file in the directory\n",
    "for fasta_file in os.listdir(fasta_dir):\n",
    "    if fasta_file.endswith(\".fa\") or fasta_file.endswith(\".fasta\"):\n",
    "        file_path = os.path.join(fasta_dir, fasta_file)\n",
    "        print(file_path)\n",
    "        record_seq=\"\"\n",
    "        record_id=\"\"\n",
    "        for n,record in enumerate(SeqIO.parse(file_path, \"fasta\")):\n",
    "            if (n==0):\n",
    "                record_id=record.id\n",
    "            record_seq=record_seq+str(record.seq)\n",
    "        print(record_id)\n",
    "        sequences_data.append({\n",
    "            \"sequence_id\": record_id,\n",
    "            \"sequence\": str(record_seq)\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the sequence data\n",
    "df = pd.DataFrame(sequences_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# inspect the DataFrame's structure\n",
    "print(\"\\nDataFrame Information:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to my data\n",
    "labels_file_path = r'/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/csv_dataset_files/quninine_phenotype_dataset.csv'\n",
    "\n",
    "# Function to read FASTA files from a directory and extract sequences\n",
    "def read_fasta_from_dir(dir_path):\n",
    "    sequences = {}\n",
    "    for fasta_file in os.listdir(dir_path):\n",
    "        if fasta_file.endswith(\".fa\") or fasta_file.endswith(\".fasta\"):\n",
    "            file_path = os.path.join(dir_path, fasta_file)\n",
    "            for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "                sequences[record.id] = str(record.seq)\n",
    "    return sequences\n",
    "\n",
    "# Function to one-hot encode the sequence\n",
    "def one_hot_encode(seq):\n",
    "    print(\"---------------\"+str(len(seq)))\n",
    "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
    "    # return np.array([mapping[nuc] for nuc in seq.upper() if nuc in mapping])\n",
    "    return np.array([mapping[nuc] for n,nuc in enumerate(seq.upper()) if ((n<1000000))])\n",
    "\n",
    "# Read sequences from the FASTA directory\n",
    "sequences = read_fasta_from_dir(fasta_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/csv_dataset_files/quninine_phenotype_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Debug: Check if the file exists\n",
    "if os.path.exists(labels_file_path):\n",
    "    print(f\"File exists: {labels_file_path}\")\n",
    "else:\n",
    "    print(f\"File not found: {labels_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read with encoding: utf-8\n"
     ]
    }
   ],
   "source": [
    "# Try reading with different encodings\n",
    "for encoding in ['utf-8', 'ISO-8859-1', 'latin1', 'cp1252']:\n",
    "    try:\n",
    "        labels_df = pd.read_csv(labels_file_path, encoding=encoding)\n",
    "        print(f\"Successfully read with encoding: {encoding}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Failed with encoding {encoding}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences read: 45\n",
      "ID: ERR029411_1.fastq, Sequence: TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaaccct...\n",
      "ID: NC_037280.1, Sequence: aaccctaaaccctaaaccctaaaccctaaaccctaaaccctaaacctaaa...\n",
      "ID: NC_000521.4, Sequence: TAAACCCTAAATCTCTAAACCCTAAAGCTATACCTAAACCCTGAAGGTTA...\n",
      "ID: NC_004318.2, Sequence: aaccctaaaccctgaaccctaaaccctaaaccctgaaccctgaaccctaa...\n",
      "ID: NC_004326.2, Sequence: ctaaaccctgaaccctaaaccctgaaccctaaaccctaaaccctgaaccc...\n",
      "Total labels read: 31\n",
      "ID: ERR012494_1.fastq, Label: Sensitive\n",
      "ID: ERR012519_1.fastq, Label: Sensitive\n",
      "ID: ERR012425_1.fastq, Label: Sensitive\n",
      "ID: ERR012424_1.fastq, Label: Sensitive\n",
      "ID: ERR029095_1.fastq, Label: Resistant\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the sequences read\n",
    "print(f\"Total sequences read: {len(sequences)}\")\n",
    "for seq_id, seq in list(sequences.items())[:5]:  # Print first 5 sequences\n",
    "    print(f\"ID: {seq_id}, Sequence: {seq[:50]}...\")\n",
    "\n",
    "# Read labels from CSV file\n",
    "labels_df = pd.read_csv(labels_file_path)\n",
    "labels_dict = labels_df.set_index('sequence_id').to_dict()['label']  # Assuming 'label' column for binary classification\n",
    "\n",
    "# Debug: Check the labels read\n",
    "print(f\"Total labels read: {len(labels_dict)}\")\n",
    "for seq_id, label in list(labels_dict.items())[:5]:  # Print first 5 labels\n",
    "    print(f\"ID: {seq_id}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------23292141\n",
      "---------------23287178\n",
      "---------------23292541\n",
      "---------------23292457\n",
      "---------------23289447\n",
      "---------------23270800\n",
      "---------------23287492\n",
      "---------------23286572\n",
      "---------------23274363\n",
      "---------------23292461\n",
      "---------------23285585\n",
      "---------------23285407\n",
      "---------------23292472\n",
      "---------------23292287\n",
      "---------------23286900\n",
      "---------------23251041\n",
      "---------------23255091\n",
      "---------------23292399\n",
      "---------------23292372\n",
      "---------------23265735\n",
      "---------------23292244\n",
      "---------------23289777\n",
      "---------------23252337\n",
      "---------------23258039\n",
      "---------------23289229\n",
      "---------------23292393\n",
      "---------------23286531\n",
      "---------------23292541\n",
      "---------------23255999\n",
      "[(4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,)]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the sequences and labels for model training\n",
    "encoded_sequences = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "df_dict = df.to_dict(\"records\")\n",
    "\n",
    "for seq_dict in df_dict:\n",
    "    if seq_dict['sequence_id'] in labels_dict:\n",
    "        # Encode the sequence and flatten it\n",
    "        encoded_sequences.append(one_hot_encode(seq_dict['sequence'].upper()).flatten())\n",
    "        # Append the corresponding label(s) from the dictionary\n",
    "        labels.append(labels_dict[seq_dict['sequence_id']].split(','))\n",
    "\n",
    "# Convert labels to a suitable format for training/prediction\n",
    "# Assuming binary classification with a single label per sample:\n",
    "labels = [label[0] if isinstance(label, list) else label for label in labels]\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert encoded sequences to a numpy array\n",
    "print([f.shape for f in encoded_sequences])\n",
    "encoded_sequences = np.array(encoded_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print (encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Resistant' 'Sensitive' 'Resistant' 'Sensitive' 'Sensitive' 'Sensitive'\n",
      " 'Resistant' 'Sensitive' 'Sensitive' 'Resistant' 'Sensitive' 'Sensitive'\n",
      " 'Resistant' 'Resistant' 'Sensitive' 'Resistant' 'Resistant' 'Sensitive'\n",
      " 'Sensitive' 'Sensitive' 'Resistant' 'Sensitive' 'Resistant' 'Sensitive'\n",
      " 'Resistant' 'Resistant' 'Sensitive' 'Sensitive' 'Sensitive']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded sequences shape: (29, 4000000)\n",
      "First encoded sequence: [0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the encoded sequences\n",
    "print(f\"Encoded sequences shape: {encoded_sequences.shape}\")\n",
    "if encoded_sequences.size > 0:\n",
    "    print(f\"First encoded sequence: {encoded_sequences[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 4000000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Resistant', 'Sensitive', 'Resistant', 'Sensitive', 'Sensitive',\n",
       "       'Sensitive', 'Resistant', 'Sensitive', 'Sensitive', 'Resistant',\n",
       "       'Sensitive', 'Sensitive', 'Resistant', 'Resistant', 'Sensitive',\n",
       "       'Resistant', 'Resistant', 'Sensitive', 'Sensitive', 'Sensitive',\n",
       "       'Resistant', 'Sensitive', 'Resistant', 'Sensitive', 'Resistant',\n",
       "       'Resistant', 'Sensitive', 'Sensitive', 'Sensitive'], dtype='<U9')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (23, 4000000)\n",
      "y_train shape: (23,)\n",
      "Unique labels in y_train: ['Resistant' 'Sensitive']\n",
      "#####################################################\n",
      "----- CV ---  1\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(71357) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(71358) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(71359) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(71360) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(71361) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(71362) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(71363) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(71364) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 4}\n",
      "Best cross-validation score: 0.77\n",
      "Model is fitted. Proceeding with predictions.\n",
      "Accuracy : 0.4\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  2\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 8}\n",
      "Best cross-validation score: 0.62\n",
      "Model is fitted. Proceeding with predictions.\n",
      "Accuracy : 1.0\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  3\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 2}\n",
      "Best cross-validation score: 0.72\n",
      "Model is fitted. Proceeding with predictions.\n",
      "Accuracy : 0.4\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  4\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 2}\n",
      "Best cross-validation score: 0.53\n",
      "Model is fitted. Proceeding with predictions.\n",
      "Accuracy : 0.0\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 8}\n",
      "Best cross-validation score: 0.63\n",
      "Model is fitted. Proceeding with predictions.\n",
      "Accuracy : 0.5\n",
      "***************************\n",
      "--------------------------------------------------\n",
      "Mean accuracy:  0.45999999999999996\n",
      "Stdev accuracy:  0.35777087639996635\n",
      "--------------------------------------------------\n",
      "Mean precision:  0.5599999999999999\n",
      "Stdev precision:  0.433589667773576\n",
      "--------------------------------------------------\n",
      "Mean recall:  0.6666666666666667\n",
      "Stdev recall:  0.4714045207910317\n",
      "--------------------------------------------------\n",
      "Mean f1:  0.5285714285714286\n",
      "Stdev f1:  0.35571141708539233\n",
      "--------------------------------------------------\n",
      "Mean roc_auc:  0.21666666666666665\n",
      "Stdev roc_auc:  0.30956959368344517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import statistics\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "# Assuming encoded_sequences and labels have been correctly prepared\n",
    "if len(encoded_sequences) > 0 and len(labels) > 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        encoded_sequences, \n",
    "        labels, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Ensure y_train and y_test are 1D arrays\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "\n",
    "    # Print to debug shape and unique labels\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"Unique labels in y_train:\", np.unique(y_train))\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [2, 4, 8],\n",
    "        'max_depth': [1, 5, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    ls_accuracy = []\n",
    "    ls_precision = []\n",
    "    ls_recall = []\n",
    "    ls_f1 = []\n",
    "    ls_roc_auc = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        print(\"#####################################################\")\n",
    "        print(\"----- CV --- \", (i + 1))\n",
    "\n",
    "        # Create a new RandomForestClassifier instance for each fold\n",
    "        clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        X_train_cv = X_train[train_index]\n",
    "        X_test_cv = X_train[test_index]\n",
    "\n",
    "        y_train_cv = y_train[train_index]\n",
    "        y_test_cv = y_train[test_index]\n",
    "\n",
    "        # Perform grid search, which fits the model\n",
    "        grid_search = GridSearchCV(clf, param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "        grid_search.fit(X_train_cv, y_train_cv)  # Model is fitted during this process\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print(\"Best parameters found: \", grid_search.best_params_)\n",
    "        print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "        # Use the best estimator from grid search (this is the fitted model)\n",
    "        best_clf = grid_search.best_estimator_\n",
    "\n",
    "        # *** Added Debugging ***\n",
    "        # Checking if the model is actually fitted before predictions\n",
    "        try:\n",
    "            if not hasattr(best_clf, \"n_estimators\"):\n",
    "                raise NotFittedError(\"Model is not properly fitted. Ensure fit() has been called.\")\n",
    "            print(\"Model is fitted. Proceeding with predictions.\")\n",
    "\n",
    "            # Predict using the fitted model\n",
    "            y_pred = best_clf.predict(X_test_cv)\n",
    "            y_proba = best_clf.predict_proba(X_test_cv)[:, 1]\n",
    "\n",
    "            # Calculate and print performance metrics\n",
    "            accuracy = accuracy_score(y_test_cv, y_pred)\n",
    "            precision = precision_score(y_test_cv, y_pred, pos_label='Sensitive')\n",
    "            recall = recall_score(y_test_cv, y_pred, pos_label='Sensitive')\n",
    "            f1 = f1_score(y_test_cv, y_pred, pos_label='Sensitive')\n",
    "\n",
    "            # Check for the ROC AUC score (only if y_test_cv has more than one class)\n",
    "            roc_auc = 0\n",
    "            if (np.unique(y_test_cv).shape[0] > 1) and (np.unique(y_proba).shape[0] > 1):\n",
    "                roc_auc = roc_auc_score(y_test_cv, y_proba)\n",
    "\n",
    "            print(\"Accuracy :\", accuracy)\n",
    "            print(\"***************************\")\n",
    "\n",
    "            # Append results to lists for later aggregation\n",
    "            ls_accuracy.append(accuracy)\n",
    "            ls_precision.append(precision)\n",
    "            ls_recall.append(recall)\n",
    "            ls_f1.append(f1)\n",
    "            ls_roc_auc.append(roc_auc)\n",
    "\n",
    "        except NotFittedError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue  # Skip the current fold if model is not fitted\n",
    "\n",
    "    # Print aggregated results\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean accuracy: \", np.mean(np.array(ls_accuracy)))\n",
    "    print(\"Stdev accuracy: \", statistics.stdev(ls_accuracy))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean precision: \", np.mean(np.array(ls_precision)))\n",
    "    print(\"Stdev precision: \", statistics.stdev(ls_precision))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean recall: \", np.mean(np.array(ls_recall)))\n",
    "    print(\"Stdev recall: \", statistics.stdev(ls_recall))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean f1: \", np.mean(np.array(ls_f1)))\n",
    "    print(\"Stdev f1: \", statistics.stdev(ls_f1))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean roc_auc: \", np.mean(np.array(ls_roc_auc)))\n",
    "    print(\"Stdev roc_auc: \", statistics.stdev(ls_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_imp=best_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000000,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_imp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02609890109890109,\n",
       " 0.023989898989898988,\n",
       " 0.125,\n",
       " 0.09890109890109891,\n",
       " 0.02609890109890109,\n",
       " 0.031666666666666676,\n",
       " 0.10101010101010101,\n",
       " 0.10124999999999999,\n",
       " 0.09890109890109891,\n",
       " 0.02827380952380953,\n",
       " 0.09672619047619047,\n",
       " 0.09333333333333332,\n",
       " 0.023750000000000007,\n",
       " 0.125]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in fts_imp if _>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_index=np.where(fts_imp>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 549693,  833224, 1355951, 1417687, 1970322, 2515049, 2750339,\n",
       "        2807868, 3184620, 3240214, 3327960, 3587847, 3609338, 3639948]),)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sequences.shape[1]/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "i=0\n",
    "\n",
    "ls_i=[]\n",
    "\n",
    "while(counter<encoded_sequences.shape[1]):\n",
    "    \n",
    "    counter_old=counter\n",
    "    counter=counter+4\n",
    "    \n",
    "    for g in range(4):\n",
    "        # print(\"n\")\n",
    "        _\n",
    "    \n",
    "    for k in imp_index[0]:\n",
    "\n",
    "        if (k>=counter_old and k<=counter):\n",
    "            ls_i.append(i)\n",
    "            \n",
    "    i=i+1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[137423,\n",
       " 208305,\n",
       " 208306,\n",
       " 338987,\n",
       " 354421,\n",
       " 492580,\n",
       " 628762,\n",
       " 687584,\n",
       " 701966,\n",
       " 701967,\n",
       " 796154,\n",
       " 796155,\n",
       " 810053,\n",
       " 831989,\n",
       " 831990,\n",
       " 896961,\n",
       " 902334,\n",
       " 909986,\n",
       " 909987]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_f={}\n",
    "for f in ls_i:\n",
    "    dict_f[f]=[]\n",
    "    \n",
    "for seq_dict in df_dict:\n",
    "    if seq_dict['sequence_id'] in labels_dict:\n",
    "        for f in ls_i:\n",
    "            dict_f[f].append(seq_dict['sequence'].upper()[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{137423: ['A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'G',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'G',\n",
       "  'C',\n",
       "  'T'],\n",
       " 208305: ['A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A'],\n",
       " 208306: ['G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'G',\n",
       "  'G',\n",
       "  'C',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'G',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A'],\n",
       " 338987: ['A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'G',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T'],\n",
       " 354421: ['C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T'],\n",
       " 492580: ['C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'G',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A'],\n",
       " 628762: ['C',\n",
       "  'G',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'C',\n",
       "  'G',\n",
       "  'T',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'G',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A'],\n",
       " 687584: ['T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A'],\n",
       " 701966: ['T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'C',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T'],\n",
       " 701967: ['A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T'],\n",
       " 796154: ['A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T'],\n",
       " 796155: ['C',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'G',\n",
       "  'A'],\n",
       " 810053: ['A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'C',\n",
       "  'C',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'C',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'A',\n",
       "  'A'],\n",
       " 831989: ['A',\n",
       "  'G',\n",
       "  'G',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'G',\n",
       "  'A',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'C'],\n",
       " 831990: ['A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T'],\n",
       " 896961: ['A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'G',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'C',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A'],\n",
       " 902334: ['A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T'],\n",
       " 909986: ['A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A'],\n",
       " 909987: ['T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'G']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dict_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving model with pickle: [Errno 20] Not a directory: '../pickle_files/quinine_phenotype.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# # # Assume X_train and y_train are already defined\n",
    "# # # X_train: Features for training\n",
    "# # # y_train: Labels for training\n",
    "\n",
    "# # # Step 1: Create and fit the RandomForest model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# # # Step 2: Fit the model with training data\n",
    "state_changed = model.fit(X_train, y_train)\n",
    "\n",
    "# # # Step 3: Save the fitted model\n",
    "try:\n",
    "    # with open('/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/pickle_files/quinine_phenotype.pkl', 'wb') as f:\n",
    "    with open('../pickle_files/quinine_phenotype.pkl', 'wb') as f:\n",
    "        pickle.dump(state_changed, f)\n",
    "    print(\"Model saved with pickle.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model with pickle: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../datadict_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(dict_f)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save the DataFrame as a CSV file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# df.to_csv('datadict.csv', index=False)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# df.to_csv('/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/datadict_files/quinine_phenotype_datadict.csv', index=False)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../datadict_files/quinine_phenotype_datadict.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDictionary saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquinine_phenotype_datadict.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/lib/python3.10/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../datadict_files'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame.from_dict(dict_f)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "# df.to_csv('datadict.csv', index=False)\n",
    "# df.to_csv('/opt/anaconda3/envs/ML-Project-on-Resistance-Prediction/resistance-prediction/datadict_files/quinine_phenotype_datadict.csv', index=False)\n",
    "df.to_csv('../datadict_files/quinine_phenotype_datadict.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Dictionary saved as 'quinine_phenotype_datadict.csv'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
