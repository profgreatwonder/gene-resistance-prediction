{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence1.fa\n",
      "ERR012226_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence10.fa\n",
      "ERR012227_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence11.fa\n",
      "ERR012228_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence12.fa\n",
      "ERR012232_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence13.fa\n",
      "ERR012260_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence14.fa\n",
      "ERR012269_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence15.fa\n",
      "ERR012274_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence16.fa\n",
      "ERR012277_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence17.fa\n",
      "ERR012287_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence18.fa\n",
      "ERR012311_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence19.fa\n",
      "ERR012317_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence2.fa\n",
      "ERR012328_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence20.fa\n",
      "ERR012330_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence21.fa\n",
      "ERR012353_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence22.fa\n",
      "ERR012409_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence23.fa\n",
      "ERR012424_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence24.fa\n",
      "ERR012425_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence25.fa\n",
      "ERR012428_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence26.fa\n",
      "ERR012446_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence27.fa\n",
      "ERR012462_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence28.fa\n",
      "ERR012469_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence29.fa\n",
      "ERR012481_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence3.fa\n",
      "ERR012493_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence30.fa\n",
      "ERR012494_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence31.fa\n",
      "ERR012509_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence32.fa\n",
      "ERR012518_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence33.fa\n",
      "ERR012519_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence4.fa\n",
      "ERR012762_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence5.fa\n",
      "ERR029083_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence6.fa\n",
      "ERR029095_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence7.fa\n",
      "ERR029096_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence8.fa\n",
      "ERR029411_1.fastq\n",
      "C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\\consensus_sequence9.fa\n",
      "ERR205935_1.fastq\n",
      "First few rows of the DataFrame:\n",
      "         sequence_id                                           sequence\n",
      "0  ERR012226_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "1  ERR012227_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "2  ERR012228_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "3  ERR012232_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "4  ERR012260_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "\n",
      "DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   sequence_id  33 non-null     object\n",
      " 1   sequence     33 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 660.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Correct path to your directory containing FASTA files\n",
    "fasta_dir = r\"C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences\"\n",
    "# List to store sequence data\n",
    "sequences_data = []\n",
    "\n",
    "# Loop through each FASTA file in the directory\n",
    "for fasta_file in os.listdir(fasta_dir):\n",
    "    if fasta_file.endswith(\".fa\") or fasta_file.endswith(\".fasta\"):\n",
    "        file_path = os.path.join(fasta_dir, fasta_file)\n",
    "        print(file_path)\n",
    "        record_seq=\"\"\n",
    "        record_id=\"\"\n",
    "        for n,record in enumerate(SeqIO.parse(file_path, \"fasta\")):\n",
    "            if (n==0):\n",
    "                record_id=record.id\n",
    "            record_seq=record_seq+str(record.seq)\n",
    "        print(record_id)\n",
    "        sequences_data.append({\n",
    "            \"sequence_id\": record_id,\n",
    "            \"sequence\": str(record_seq)\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the sequence data\n",
    "df = pd.DataFrame(sequences_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# inspect the DataFrame's structure\n",
    "print(\"\\nDataFrame Information:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to my data\n",
    "fasta_dir_path = r'C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\consensus_sequences'\n",
    "\n",
    "labels_file_path = r'C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\Drugs_Phenotype\\Mefloquine Phenotype Dataset for training without NA.csv'\n",
    "#'C:\\Users\\FEDGEN-LAB1-SYS7\\OneDrive\\Desktop\\Mercy Akinwale\\Drugs_Phenotype\\DHA Phenotype Dataset for training.xlsx'\n",
    "# Function to read FASTA files from a directory and extract sequences\n",
    "def read_fasta_from_dir(dir_path):\n",
    "    sequences = {}\n",
    "    for fasta_file in os.listdir(dir_path):\n",
    "        if fasta_file.endswith(\".fa\") or fasta_file.endswith(\".fasta\"):\n",
    "            file_path = os.path.join(dir_path, fasta_file)\n",
    "            for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "                sequences[record.id] = str(record.seq)\n",
    "    return sequences\n",
    "\n",
    "# Function to one-hot encode the sequence\n",
    "def one_hot_encode(seq):\n",
    "    print(\"---------------\"+str(len(seq)))\n",
    "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
    "    # return np.array([mapping[nuc] for nuc in seq.upper() if nuc in mapping])\n",
    "    return np.array([mapping[nuc] for n,nuc in enumerate(seq.upper()) if ((n<1000000))])\n",
    "\n",
    "# Read sequences from the FASTA directory\n",
    "sequences = read_fasta_from_dir(fasta_dir_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (one_hot_encode(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences read: 46\n",
      "ID: ERR012226_1.fastq, Sequence: TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaaccct...\n",
      "ID: NC_037280.1, Sequence: aaccctaaaccctaaaccctaaaccctaaaccctaaaccctaaacctaaa...\n",
      "ID: NC_000521.4, Sequence: TAAACCCTAAATCTCTAAACCCTAAAGCTATACCTAAACCCTGAAGGTTA...\n",
      "ID: NC_004318.2, Sequence: aaccctaaaccctgaaccctaaaccctaaaccctgaaccctgaaccctaa...\n",
      "ID: NC_004326.2, Sequence: ctaaaccctgaaccctaaaccctgaaccctaaaccctaaaccctgaaccc...\n",
      "Total labels read: 32\n",
      "ID: ERR012494_1.fastq, Label: Resistant\n",
      "ID: ERR012519_1.fastq, Label: Sensitive\n",
      "ID: ERR012425_1.fastq, Label: Sensitive\n",
      "ID: ERR012424_1.fastq, Label: Sensitive\n",
      "ID: ERR029095_1.fastq, Label: Resistant\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the sequences read\n",
    "print(f\"Total sequences read: {len(sequences)}\")\n",
    "for seq_id, seq in list(sequences.items())[:5]:  # Print first 5 sequences\n",
    "    print(f\"ID: {seq_id}, Sequence: {seq[:50]}...\")\n",
    "\n",
    "# Read labels from CSV file\n",
    "labels_df = pd.read_csv(labels_file_path)\n",
    "labels_dict = labels_df.set_index('sequence_id').to_dict()['label']  # Assuming 'label' column for binary classification\n",
    "\n",
    "# Debug: Check the labels read\n",
    "print(f\"Total labels read: {len(labels_dict)}\")\n",
    "for seq_id, label in list(labels_dict.items())[:5]:  # Print first 5 labels\n",
    "    print(f\"ID: {seq_id}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------23292372\n",
      "---------------23292541\n",
      "---------------23285585\n",
      "---------------23292393\n",
      "---------------23292457\n",
      "---------------23287492\n",
      "---------------23289777\n",
      "---------------23286531\n",
      "---------------23255091\n",
      "---------------23292399\n",
      "---------------23285407\n",
      "---------------23289447\n",
      "---------------23286572\n",
      "---------------23252337\n",
      "---------------23292541\n",
      "---------------23287178\n",
      "---------------23292547\n",
      "---------------23258039\n",
      "---------------23289229\n",
      "---------------23286900\n",
      "---------------23265735\n",
      "---------------23292287\n",
      "---------------23270800\n",
      "---------------23274363\n",
      "---------------23255999\n",
      "---------------23251041\n",
      "---------------23292244\n",
      "---------------23288862\n",
      "---------------23292472\n",
      "---------------23292141\n",
      "---------------23292461\n",
      "[(4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,), (4000000,)]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the sequences and labels for model training\n",
    "encoded_sequences = []\n",
    "labels = []\n",
    "\n",
    "df_dict=df.to_dict(\"records\")\n",
    "\n",
    "#display(labels_dict)\n",
    "\n",
    "for seq_dict in df_dict:\n",
    "    #print(seq_dict['sequence_id'])\n",
    "    if seq_dict['sequence_id'] in labels_dict:\n",
    "        #print(len(one_hot_encode(seq_dict['sequence'])))\n",
    "        #jjfjf\n",
    "        encoded_sequences.append(one_hot_encode(seq_dict['sequence'].upper()).flatten())\n",
    "        labels.append(labels_dict[seq_dict['sequence_id']].split(','))\n",
    "\n",
    "# hhhhg\n",
    "\n",
    "# Convert to numpy arrays\n",
    "print([f.shape for f in encoded_sequences])\n",
    "\n",
    "encoded_sequences = np.array(encoded_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded sequences shape: (31, 4000000)\n",
      "First encoded sequence: [0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the encoded sequences\n",
    "print(f\"Encoded sequences shape: {encoded_sequences.shape}\")\n",
    "if encoded_sequences.size > 0:\n",
    "    print(f\"First encoded sequence: {encoded_sequences[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Sensitive'],\n",
       "       ['Resistat'],\n",
       "       ['Sensitive'],\n",
       "       ['Sensitive'],\n",
       "       ['Sensitive'],\n",
       "       ['Resistant'],\n",
       "       ['Sensitive'],\n",
       "       ['Sensitive'],\n",
       "       ['Sensitive'],\n",
       "       ['Resistant'],\n",
       "       ['Sensitive'],\n",
       "       ['Resistant'],\n",
       "       ['Sensitive'],\n",
       "       ['Resistant'],\n",
       "       ['Sensitive'],\n",
       "       ['Sensitive'],\n",
       "       ['Resistant'],\n",
       "       ['Resistant'],\n",
       "       ['Resistant'],\n",
       "       ['Sensitive'],\n",
       "       ['Sensitive'],\n",
       "       ['Resistant'],\n",
       "       ['Resistant'],\n",
       "       ['Sensitive'],\n",
       "       ['Sensitive'],\n",
       "       ['Resistant'],\n",
       "       ['Resistant'],\n",
       "       ['Resistant'],\n",
       "       ['Resistant'],\n",
       "       ['Resistant'],\n",
       "       ['Resistant']], dtype='<U9')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4000000)\n",
      "#####################################################\n",
      "----- CV ---  1\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 4}\n",
      "Best cross-validation score: 0.58\n",
      "Accuracy : 0.6\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  2\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 2}\n",
      "Best cross-validation score: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FEDGEN-LAB1-SYS7\\.conda\\envs\\mercyproject\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.2\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  3\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 2}\n",
      "Best cross-validation score: 0.62\n",
      "Accuracy : 0.4\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  4\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 2}\n",
      "Best cross-validation score: 0.65\n",
      "Accuracy : 0.2\n",
      "***************************\n",
      "#####################################################\n",
      "----- CV ---  5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found:  {'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 2}\n",
      "Best cross-validation score: 0.45\n",
      "Accuracy : 0.5\n",
      "***************************\n",
      "--------------------------------------------------\n",
      "Mean accuracy:  0.38\n",
      "Stdev accuracy:  0.17888543819998318\n",
      "--------------------------------------------------\n",
      "Mean precision:  0.5466666666666666\n",
      "Stdev precision:  0.4407065034943576\n",
      "--------------------------------------------------\n",
      "Mean recall:  0.4333333333333333\n",
      "Stdev recall:  0.36514837167011077\n",
      "--------------------------------------------------\n",
      "Mean f1:  0.41428571428571426\n",
      "Stdev f1:  0.2616882221720778\n",
      "--------------------------------------------------\n",
      "Mean roc_auc:  0.3416666666666667\n",
      "Stdev roc_auc:  0.3151278400198173\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import statistics\n",
    "\n",
    "# subset_selection=3500000\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "if len(encoded_sequences) > 0 and len(labels) > 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(encoded_sequences[:,:], np.array(labels)[:,:], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [2, 4, 6],\n",
    "        'max_depth': [1, 3, 6, 9],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "\n",
    "    }\n",
    "    \n",
    "    print(X_train.shape)\n",
    "\n",
    "    # Convert y_train to a NumPy array and ensure it is 1D\n",
    "    y_train = np.array(y_train).ravel()\n",
    "\n",
    "    # Train a binary classification model using Random Forest\n",
    "    \n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    ls_accuracy=[]\n",
    "    ls_precision=[]\n",
    "    ls_recall=[]\n",
    "    ls_f1=[]\n",
    "    ls_roc_auc=[]\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        \n",
    "        print(\"#####################################################\")\n",
    "        print(\"----- CV --- \",(i+1))\n",
    "        \n",
    "        clf = RandomForestClassifier(random_state=42)\n",
    "        \n",
    "        X_train_cv=X_train[train_index]\n",
    "        X_test_cv=X_train[test_index]\n",
    "        \n",
    "        y_train_cv=y_train[train_index]\n",
    "        y_test_cv=y_train[test_index]\n",
    "\n",
    "        # Perform grid search\n",
    "        grid_search = GridSearchCV(clf, param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "        grid_search.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print(\"Best parameters found: \", grid_search.best_params_)\n",
    "        print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "        # Use the best estimator from grid search\n",
    "        best_clf = grid_search.best_estimator_\n",
    "        \n",
    "        y_pred = best_clf.predict(X_test_cv)\n",
    "        y_proba = best_clf.predict_proba(X_test_cv)[:, 1]\n",
    "\n",
    "        # Calculate and print performance metrics\n",
    "        accuracy = accuracy_score(y_test_cv, y_pred)\n",
    "        \n",
    "        precision = precision_score(y_test_cv, y_pred, pos_label='Sensitive')\n",
    "        recall = recall_score(y_test_cv, y_pred, pos_label='Sensitive')\n",
    "        f1 = f1_score(y_test_cv, y_pred, pos_label='Sensitive')\n",
    "        \n",
    "        roc_auc=0\n",
    "        if ((np.unique(y_test_cv).shape[0]>1) and (np.unique(y_proba).shape[0]>1)):\n",
    "            roc_auc = roc_auc_score(y_test_cv, y_proba)\n",
    "        \n",
    "        print(\"Accuracy :\",accuracy)\n",
    "        print(\"***************************\")\n",
    "        \n",
    "        ls_accuracy.append(accuracy)\n",
    "        ls_precision.append(precision)\n",
    "        ls_recall.append(recall)\n",
    "        ls_f1.append(f1)\n",
    "        ls_roc_auc.append(roc_auc)\n",
    "    \n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean accuracy: \", np.mean(np.array(ls_accuracy)))\n",
    "    print(\"Stdev accuracy: \",statistics.stdev(ls_accuracy))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean precision: \", np.mean(np.array(ls_precision)))\n",
    "    print(\"Stdev precision: \",statistics.stdev(ls_precision))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean recall: \", np.mean(np.array(ls_recall)))\n",
    "    print(\"Stdev recall: \",statistics.stdev(ls_recall))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean f1: \", np.mean(np.array(ls_f1)))\n",
    "    print(\"Stdev f1: \",statistics.stdev(ls_f1))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Mean roc_auc: \", np.mean(np.array(ls_roc_auc)))\n",
    "    print(\"Stdev roc_auc: \",statistics.stdev(ls_roc_auc))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_imp=best_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000000,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_imp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in fts_imp if _>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_index=np.where(fts_imp>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1494302, 1527995, 1647964, 1761974, 2428465, 3043709, 3114454,\n",
       "        3608978], dtype=int64),)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sequences.shape[1]/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "i=0\n",
    "\n",
    "ls_i=[]\n",
    "\n",
    "while(counter<encoded_sequences.shape[1]):\n",
    "    \n",
    "    counter_old=counter\n",
    "    counter=counter+4\n",
    "    \n",
    "    for g in range(4):\n",
    "        # print(\"n\")\n",
    "        _\n",
    "    \n",
    "    for k in imp_index[0]:\n",
    "\n",
    "        if (k>=counter_old and k<=counter):\n",
    "            ls_i.append(i)\n",
    "            \n",
    "    i=i+1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[373575, 381998, 411990, 411991, 440493, 607116, 760927, 778613, 902244]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_f={}\n",
    "for f in ls_i:\n",
    "    dict_f[f]=[]\n",
    "    \n",
    "for seq_dict in df_dict:\n",
    "    if seq_dict['sequence_id'] in labels_dict:\n",
    "        for f in ls_i:\n",
    "            dict_f[f].append(seq_dict['sequence'].upper()[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{373575: ['A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'G',\n",
       "  'A'],\n",
       " 381998: ['A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'G',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'G',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'G',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A'],\n",
       " 411990: ['A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'C',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'C',\n",
       "  'C',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C'],\n",
       " 411991: ['T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'G',\n",
       "  'C',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G'],\n",
       " 440493: ['T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'T',\n",
       "  'G',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A'],\n",
       " 607116: ['T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'C',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T'],\n",
       " 760927: ['A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'G',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'A',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A'],\n",
       " 778613: ['A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'C',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'C',\n",
       "  'A',\n",
       "  'A',\n",
       "  'T'],\n",
       " 902244: ['A',\n",
       "  'T',\n",
       "  'T',\n",
       "  'T',\n",
       "  'G',\n",
       "  'A',\n",
       "  'C',\n",
       "  'T',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'T',\n",
       "  'A',\n",
       "  'G',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'G',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'C',\n",
       "  'G',\n",
       "  'T',\n",
       "  'A',\n",
       "  'G',\n",
       "  'T',\n",
       "  'G',\n",
       "  'G',\n",
       "  'A']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dict_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>373575</th>\n",
       "      <th>381998</th>\n",
       "      <th>411990</th>\n",
       "      <th>411991</th>\n",
       "      <th>440493</th>\n",
       "      <th>607116</th>\n",
       "      <th>760927</th>\n",
       "      <th>778613</th>\n",
       "      <th>902244</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   373575 381998 411990 411991 440493 607116 760927 778613 902244\n",
       "0       A      A      A      T      T      T      A      A      A\n",
       "1       T      A      A      T      T      T      A      A      T\n",
       "2       T      T      T      T      C      A      T      T      T\n",
       "3       T      A      T      T      T      A      T      T      T\n",
       "4       G      T      C      A      G      C      C      T      G\n",
       "5       A      C      T      T      T      T      A      C      A\n",
       "6       C      G      T      A      A      A      G      C      C\n",
       "7       A      A      A      T      T      T      A      T      T\n",
       "8       T      T      C      T      T      A      T      A      G\n",
       "9       T      T      C      A      G      A      G      T      T\n",
       "10      G      A      T      T      T      T      A      A      A\n",
       "11      T      G      G      T      T      T      A      A      T\n",
       "12      A      T      T      T      C      A      A      C      A\n",
       "13      C      A      A      T      T      A      T      T      G\n",
       "14      A      T      C      A      G      T      T      G      G\n",
       "15      T      T      C      A      G      A      A      A      A\n",
       "16      A      G      C      T      T      A      T      A      A\n",
       "17      A      G      G      C      T      T      A      T      G\n",
       "18      T      C      T      T      G      T      T      T      T\n",
       "19      A      T      T      G      T      A      G      A      A\n",
       "20      T      A      A      C      A      A      T      A      G\n",
       "21      A      A      T      T      A      C      A      T      A\n",
       "22      T      C      T      T      A      A      G      A      A\n",
       "23      T      A      T      C      T      A      A      C      A\n",
       "24      A      A      T      T      A      T      A      T      C\n",
       "25      A      T      T      A      T      C      C      G      G\n",
       "26      A      A      A      T      A      G      A      T      T\n",
       "27      A      A      T      T      T      T      G      T      A\n",
       "28      A      C      T      T      T      T      A      T      G\n",
       "29      A      G      A      T      T      A      A      C      T\n",
       "30      A      A      A      T      T      A      A      A      G\n",
       "31      G      T      A      T      A      T      A      A      G\n",
       "32      A      A      C      G      A      T      A      T      A"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(dict_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To print the file out as a csv\n",
    "# Specify the file name\n",
    "file_name = 'pd.DataFrame.from_dict(dict_f)'\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_sequences, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sequence_id                                           sequence\n",
      "0   ERR012226_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "1   ERR012227_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "2   ERR012228_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "3   ERR012232_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "4   ERR012260_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "5   ERR012269_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "6   ERR012274_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "7   ERR012277_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "8   ERR012287_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "9   ERR012311_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "10  ERR012317_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "11  ERR012328_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "12  ERR012330_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "13  ERR012353_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "14  ERR012409_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "15  ERR012424_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "16  ERR012425_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "17  ERR012428_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "18  ERR012446_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "19  ERR012462_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "20  ERR012469_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "21  ERR012481_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "22  ERR012493_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "23  ERR012494_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "24  ERR012509_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "25  ERR012518_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "26  ERR012519_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "27  ERR012762_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "28  ERR029083_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "29  ERR029095_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "30  ERR029096_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "31  ERR029411_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n",
      "32  ERR205935_1.fastq  TGAACCCTaaaacctaaaccctaaaccctaaaccctgaaccctaaa...\n"
     ]
    }
   ],
   "source": [
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FEDGEN-LAB1-SYS7\\.conda\\envs\\mercyproject\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428571428571\n",
      "Precision: 0.8571428571428571\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9230769230769231\n",
      "ROC AUC: 0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode labels to binary format (0 and 1)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Train the model using encoded labels\n",
    "clf.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predict using encoded labels\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "precision = precision_score(y_test_encoded, y_pred)\n",
    "recall = recall_score(y_test_encoded, y_pred)\n",
    "f1 = f1_score(y_test_encoded, y_pred)\n",
    "roc_auc = roc_auc_score(y_test_encoded, y_proba)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC: {roc_auc}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mercyproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
